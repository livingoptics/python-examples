{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37183dac",
   "metadata": {},
   "source": [
    "# Regression Notebook: Predicting Sugar Content from Grape Using Living Optics Export Reader\n",
    "This example aims to experiment with various machine learning models based on .lo data and perform regression.\n",
    "\n",
    "## Steps\n",
    "- Read the exported group from data analysis tool\n",
    "- Train regressor based on divided features & labels\n",
    "- Compare model performance by visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f95eee",
   "metadata": {},
   "source": [
    "## 1. Import libraries and Setup\n",
    "We import the libraries needed for data handling, modeling, evaluation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db188864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tools\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "\n",
    "# Machine learning models and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, r2_score\n",
    ")\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Dataset loader\n",
    "from lo_dataset_reader import DatasetReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79768b5d",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "Load the grape dataset which contains annotations, spectral data, and metadata such as sugar content and position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286d3cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load dataset using the custom DatasetReader class\n",
    "path = \"/path/to/Grapes-Dataset.zip\"\n",
    "reader = DatasetReader(dataset_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07618565",
   "metadata": {},
   "source": [
    "## 3. Convert Categorical Position to Numerical Features\n",
    "The grape position is given as a string. This function converts it into a list of three numerical values: tray number, row index, and column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting position to feature (e.g. tray16-a1 -> int)\n",
    "def position_to_numeric(pos: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Convert a position string (e.g. 'tray16-a1') into numeric features.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"tray(\\d+)-([a-z])(\\d+)\", pos)\n",
    "    if match:\n",
    "        tray, row, col = match.groups()\n",
    "        return [int(tray), ord(row) - ord('a'), int(col)]\n",
    "    return [0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94623d7",
   "metadata": {},
   "source": [
    "## 4. Metadata Extraction: Sugar Content & Position\n",
    "Loop through the dataset to extract grape positions and corresponding sugar content from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17220660",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions, sugar_contents = [], []\n",
    "\n",
    "# Extract position and sugar content for each annotated grape\n",
    "for (info, scene, spectra, _), converted_spectra, annotations, *_ in reader:\n",
    "    for ann in annotations:\n",
    "        if ann['metadata'] and ann['category_name'] == 'grapes':\n",
    "            meta = {item['field']: item['value'] for item in ann['metadata']}\n",
    "            positions.append(meta['position'])\n",
    "            sugar_contents.append(float(meta['sugar-content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2718cfb",
   "metadata": {},
   "source": [
    "## 5. Train Regression Models and Evaluate\n",
    "Train six different regression models and evaluate their performance using metrics like R2 score, MAE, MAPE, MSE, and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = np.array([position_to_numeric(pos) for pos in positions])\n",
    "y = np.array(sugar_contents)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define multiple regression models\n",
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Lasso\", Lasso()),\n",
    "    (\"Ridge\", Ridge()),\n",
    "    (\"Random Forest\", RandomForestRegressor()),\n",
    "    (\"PLS Regression\", PLSRegression()),\n",
    "    (\"SVR\", SVR())\n",
    "]\n",
    "\n",
    "# Store evaluation metrics\n",
    "metrics_df = { 'Model': [], 'R2': [], 'MAE': [], 'MAPE': [], 'MSE': [], 'RMSE': [] }\n",
    "residuals_list = []\n",
    "\n",
    "# Fit and evaluate each model\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    metrics_df['Model'].append(name)\n",
    "    metrics_df['R2'].append(r2_score(y_test, y_pred))\n",
    "    metrics_df['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    metrics_df['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    metrics_df['MSE'].append(mse)\n",
    "    metrics_df['RMSE'].append(np.sqrt(mse))\n",
    "    residuals_list.append(y_test - y_pred)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16cf2c",
   "metadata": {},
   "source": [
    "## 6. Visualise Model Performance\n",
    "Visualise how well each model performs with comparison plots including residuals, predicted vs actual, and metric bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72856f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Actual vs Predicted\n",
    "plt.subplot(2, 2, 1)\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6, label=name)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--')\n",
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.xlabel(\"Actual Sugar Content\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.legend()\n",
    "\n",
    "# Residual distributions\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(data=residuals_list)\n",
    "plt.xticks(range(len(models)), metrics_df['Model'], rotation=45)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "\n",
    "# Normalised metrics (R2, MAPE)\n",
    "plt.subplot(2, 2, 3)\n",
    "norm = metrics_df.melt(id_vars='Model', value_vars=['R2', 'MAPE'], var_name='Metric', value_name='Value')\n",
    "sns.barplot(data=norm, x='Model', y='Value', hue='Metric')\n",
    "plt.title(\"Normalised Metrics\")\n",
    "\n",
    "# Raw metrics (MAE, MSE, RMSE)\n",
    "plt.subplot(2, 2, 4)\n",
    "non_norm = metrics_df.melt(id_vars='Model', value_vars=['MAE', 'MSE', 'RMSE'], var_name='Metric', value_name='Value')\n",
    "sns.barplot(data=non_norm, x='Model', y='Value', hue='Metric')\n",
    "plt.title(\"Raw Metrics\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e8694",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "This section evaluates the performance of several regression models on predicting sugar content, using both graphical and numerical metrics.\n",
    "\n",
    "### Plot Discussion\n",
    "1. Predicted vs Actual (Top Left) : This scatter plot compares the predicted values to the actual sugar content. The diagonal dashed line represents perfect predictions (i.e., predicted = actual). Points closer to this line indicate better model performance.\n",
    "    - Observation: Random Forest predictions are more closely clustered around the diagonal, suggesting it has learned the relationship between features and sugar content better than other models.\n",
    "\n",
    "2. Residuals Distribution (Top Right) : Boxplots of residuals (actual - predicted values) help visualise the error spread for each model. A good model will have residuals centered around zero with minimal spread and few outliers.\n",
    "    - Observation: Random Forest shows a tighter residual distribution with fewer extreme outliers compared to the other models.\n",
    "\n",
    "3. Normalised Metrics (Bottom Left) : This bar chart compares models based on normalized R2 score (coefficient of determination) and MAPE (Mean Absolute Percentage Error) scores.\n",
    "    - R2 score indicates the proportion of variance explained by the model (higher is better).\n",
    "    - MAPE measures the average percentage error (lower is better).\n",
    "    - Observation: Random Forest has the highest R2 score value and a relatively low MAPE, confirming strong predictive performance.\n",
    "\n",
    "4. Raw Metrics (Bottom Right) : This plot shows the raw evaluation metrics for each model:\n",
    "    - MAE (Mean Absolute Error): Average of absolute errors.\n",
    "    - MSE (Mean Squared Error): Average of squared errors (penalizes large errors).\n",
    "    - RMSE (Root Mean Squared Error): Square root of MSE, interpretable in the same units as the target variable.\n",
    "    - Observation: Again, Random Forest has the lowest MAE, MSE, and RMSE values, further indicating superior accuracy.\n",
    "\n",
    "### Metric Definitions\n",
    "- R2 score (R-squared): Measures how well the variance in the dependent variable is explained by the model. Ranges from 0 to 1; closer to 1 means better fit.\n",
    "- MAE (Mean Absolute Error): The average absolute difference between predicted and actual values. It gives an idea of the average prediction error.\n",
    "- MSE (Mean Squared Error): Similar to MAE but squares the errors, making larger errors more significant.\n",
    "- RMSE (Root Mean Squared Error): The square root of MSE. It retains the unit of the output variable and penalizes large errors.\n",
    "- MAPE (Mean Absolute Percentage Error): The average of absolute percentage errors. It provides a sense of relative error size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75a960",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Extracted both positional and spectral features from *.lo* data\n",
    "- Compared six regression models for sugar prediction from physical positions\n",
    "- Visualised predictions, residuals, and performance metrics in detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
