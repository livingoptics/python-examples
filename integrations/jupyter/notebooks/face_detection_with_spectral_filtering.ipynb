{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../media/face_spoof_tracking_with_spectral_filtering.gif)\n",
    "\n",
    "#### Description\n",
    "We will build upon the previous example `Face detection` and see how we can use spectral information to filter between fake and real faces which wasn not possible with just the RGB video.\n",
    "\n",
    "#### Code summary\n",
    "- Setup the decoder using LO's `SpectralDecoder` with a calibration folder.\n",
    "- Load target spectra of a real face from a previously saved spectra json file.\n",
    "- Set classification threshold parameters.\n",
    "- Run face detection as before.\n",
    "- Use `spectral_roi_classifier` to filter the real faces from fake faces.\n",
    "- Use `draw_rois_and_labels` to overlay the results onto the scene.\n",
    "- Render the results.\n",
    "\n",
    "#### Living Optics APIs used\n",
    "- Decoding with `SpectralDecoder`\n",
    "- Reading using `open`\n",
    "- Formatting with `LORAWtoRGB8`\n",
    "- Filtering with `spectral_roi_claissifier`\n",
    "- Overlaying results with `draw_rois_and_labels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "# This file is subject to the terms and conditions defined in file\n",
    "# `COPYING.md`, which is part of this source code package.\n",
    "\n",
    "import cv2\n",
    "import jetson_inference\n",
    "import jetson_utils\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "from lo.sdk.api.acquisition.io.open import open as lo_open\n",
    "from lo.sdk.api.acquisition.data.formats import LORAWtoRGB8\n",
    "from lo.sdk.api.acquisition.data.decode import SpectralDecoder\n",
    "from lo.sdk.api.analysis.classifier import spectral_roi_classifier\n",
    "from lo.sdk.api.analysis.helpers import draw_rois_and_labels\n",
    "from lo.sdk.api.analysis.metrics import spectral_angles\n",
    "from lo.sdk.helpers.path import getdatastorepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "PATH_TO_LO_RAW_FILE = os.path.join(\n",
    "    getdatastorepath(),\n",
    "    \"lo\",\n",
    "    \"share\",\n",
    "    \"samples\",\n",
    "    \"face-spoofing\",\n",
    "    \"face-spoof-demo.loraw\"\n",
    ")\n",
    "\n",
    "factory_calibration_folder_DIR = os.path.join(getdatastorepath(), \"lo\", \"share\", \"samples\", \"face-spoofing\", \"demo-calibration-face-spoofing\")\n",
    "SPECTRA_JSON_PATH = os.path.join(os.getcwd(), \"..\", \"assets\", \"real_face_spectra.json\")\n",
    "\n",
    "# Define facenet detector\n",
    "net = jetson_inference.detectNet(\"facenet\", threshold=0.001)\n",
    "\n",
    "# Instantiate the spectral decoder\n",
    "decoder = SpectralDecoder.from_calibration(factory_calibration_folder_DIR)\n",
    "\n",
    "# Load target spectra\n",
    "with open(SPECTRA_JSON_PATH) as f:\n",
    "    target_spectra = np.asarray(json.load(f)[\"crosshair\"][\"y\"])\n",
    "\n",
    "# Threshold parameters\n",
    "classification_threshold = 0.06\n",
    "binary_threshold = 1 / 15\n",
    "\n",
    "RESIZE_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "setup",
     "comments",
     "common"
    ]
   },
   "source": [
    "- Define jetson-inference's detectNet\n",
    "- Instantiate the Living Optics spectral decoder object for run spectral analysis\n",
    "- Load target spectral data from a JSON file which is of the target face.\n",
    "- Set classification threshold parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run detection and spectral filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "analysis"
    ]
   },
   "outputs": [],
   "source": [
    "with lo_open(PATH_TO_LO_RAW_FILE) as f:\n",
    "    for frame in f:\n",
    "        # Decodes encoded_frame and converts scene_frame from LORAW to RGB8 format\n",
    "        metadata, scene_frame, spectra = decoder(frame, scene_decoder=LORAWtoRGB8)\n",
    "        \n",
    "        # RGB -> OpenCV's BGR\n",
    "        scene_frame = cv2.cvtColor(scene_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # The particular video we're using has been recorded upside down and so we'll flip\n",
    "        scene_frame = cv2.flip(scene_frame, 0)\n",
    "\n",
    "        # Place scene_frame into cuda for jetson inference\n",
    "        scene_frame_cuda = jetson_utils.cudaFromNumpy(scene_frame)\n",
    "                \n",
    "        # Run Jetson inference\n",
    "        detections = net.Detect(scene_frame_cuda, overlay=\"box,labels,conf\")\n",
    "\n",
    "        # Get bounding boxes' coordinates\n",
    "        bbox_coordinates = [\n",
    "            [int(obj.Left), int(obj.Top), int(obj.Width), int(obj.Height)]\n",
    "            for obj in detections\n",
    "        ]\n",
    "\n",
    "        bbox_coordinates_vertically_flipped = [\n",
    "            [int(obj.Left), scene_frame.shape[0] - int(obj.Bottom), int(obj.Width), int(obj.Height)]\n",
    "            for obj in detections\n",
    "        ]\n",
    "\n",
    "        # Use spectral information to classify real vs face faces\n",
    "        class_labels, confidences, classified_spectra, segmentations = spectral_roi_classifier(\n",
    "            spectral_list=spectra,\n",
    "            target_spectra=target_spectra,\n",
    "            metric=spectral_angles,\n",
    "            rois=bbox_coordinates_vertically_flipped,\n",
    "            sampling_coordinates=decoder.sampling_coordinates,\n",
    "            classification_threshold=classification_threshold,\n",
    "            binary_threshold=binary_threshold,\n",
    "            scale_factor=1,\n",
    "        )\n",
    "\n",
    "        # Add classified bounding boxes overlays to scene\n",
    "        display = draw_rois_and_labels(\n",
    "            scene=scene_frame,\n",
    "            rois=bbox_coordinates,\n",
    "            class_idxs=class_labels,\n",
    "            confidence=confidences,\n",
    "            colours=[(0, 0, 255), (0, 255, 0)],\n",
    "            class_labels={0: \"Fake face\", 1: \"Real face\"}\n",
    "        )\n",
    "\n",
    "        # Resize\n",
    "        display = imutils.resize(display, int(display.shape[1]*RESIZE_FACTOR))\n",
    "        \n",
    "        # Render\n",
    "        cv2.imshow(\"Preview\", display)\n",
    "\n",
    "        # Break on 'Esc' key\n",
    "        key = cv2.waitKey(20)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "analysis",
     "comments",
     "common"
    ]
   },
   "source": [
    "- The decoder takes the `.loraw` frame as input and outputs decoded spectra and formatted scene_frame according to the given formatter passed into the decoder.\n",
    "- Using the bounding boxes from jetson-inference, use LO's `spectral_roi_classifier` method to classify the bounding boxes against the target spectra.\n",
    "- Pass the output to `draw_rois_and_labels` method to add classified bounding boxes' information as overlay on top of the scene_frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "output",
     "video"
    ]
   },
   "source": [
    "![](../media/face_spoof_tracking_with_spectral_filtering.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "output",
     "comments",
     "common"
    ]
   },
   "source": [
    "This is a good example of how spectral information can give us valuable extra insight. The RGB face detection model can detect `face-like` shapes but struggles to distinguish between real and fake faces. However, the same RGB detection model model together with spectral information can further classify between real and fake faces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
