{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../media/face_spoof_tracking_rgb.gif)\n",
    "\n",
    "#### Description\n",
    "We'll compare how to use the jetson-inference to do a face detection with RGB file and LORaw file just on the `scene_view`.\n",
    "\n",
    "#### Code summary\n",
    "- We'll read frames from an existing `.loraw` file using LO's `open` api.\n",
    "- We'll then feed in the `scene_frame` into jetson-inference's detectNet model to get face detection overlays.\n",
    "- We'll then render the overlay using OpenCV.\n",
    "\n",
    "#### LO's APIs used\n",
    "- Decoding with `SpectralDecoder`\n",
    "- Reading using LO's `open`\n",
    "- Formatting with `LORAWtoRGB8`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "# This file is subject to the terms and conditions defined in file\n",
    "# `COPYING.md`, which is part of this source code package.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import jetson_inference\n",
    "import jetson_utils\n",
    "\n",
    "from lo.sdk.api.acquisition.io.open import open as lo_open\n",
    "from lo.sdk.api.acquisition.data.formats import LORAWtoRGB8\n",
    "from lo.sdk.helpers.path import getdatastorepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "PATH_TO_LO_RAW_FILE = os.path.join(\n",
    "    getdatastorepath(),\n",
    "    \"lo\",\n",
    "    \"share\",\n",
    "    \"samples\",\n",
    "    \"face-spoofing\",\n",
    "    \"face-spoof-demo.lo-raw\"\n",
    ")\n",
    "\n",
    "# Define facenet detector\n",
    "net = jetson_inference.detectNet(\"facenet\", threshold=0.01)\n",
    "\n",
    "RESIZE_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We instantiate jetson-inference's detectNet with the facenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "render"
    ]
   },
   "outputs": [],
   "source": [
    "with lo_open(PATH_TO_LO_RAW_FILE) as f:\n",
    "    for (encoded_info, encoded_frame), (scene_info, scene_frame) in f:\n",
    "        # Convert loraw -> RGB8 -> opencv's BGR\n",
    "        scene_frame = LORAWtoRGB8(scene_frame)\n",
    "        scene_frame = cv2.cvtColor(scene_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # The particular video we're using has been recorded upside down and so we'll flip\n",
    "        scene_frame = cv2.flip(scene_frame, 0)\n",
    "\n",
    "        # Place scene_frame into cuda for jetson inference\n",
    "        scene_frame_cuda = jetson_utils.cudaFromNumpy(scene_frame)\n",
    "        \n",
    "        # Resize image\n",
    "        scene_frame_cuda_resized = jetson_utils.cudaAllocMapped(\n",
    "            width=scene_frame_cuda.width * RESIZE_FACTOR,\n",
    "            height=scene_frame_cuda.height * RESIZE_FACTOR,\n",
    "            format=scene_frame_cuda.format,\n",
    "        )\n",
    "\n",
    "        jetson_utils.cudaResize(scene_frame_cuda, scene_frame_cuda_resized)\n",
    "        \n",
    "        # Run Jetson inference\n",
    "        detections = net.Detect(scene_frame_cuda_resized, overlay=\"box,labels,conf\")\n",
    "\n",
    "        # Convert scene_frame back into numpy format\n",
    "        display = jetson_utils.cudaToNumpy(scene_frame_cuda_resized)\n",
    "\n",
    "        cv2.imshow(\"Preview\", display)\n",
    "\n",
    "        # Break on 'Esc' key\n",
    "        key = cv2.waitKey(20)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "render",
     "comments",
     "common"
    ]
   },
   "source": [
    "- Instantiate LO's `open` context with the path to the `.loraw` file.\n",
    "- Convert to RGB8 using `LORAWtoRGB8` then to BGR for OpenCV's format.\n",
    "- Run the detection using jetson-inference.\n",
    "- Render the scene with detection overlays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "output",
     "video"
    ]
   },
   "source": [
    "![](../media/face_spoof_tracking.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
